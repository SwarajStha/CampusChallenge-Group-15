This directory contains all the codes, files, sample data used and the results for the Campus Challenge - Investing with AI project.

Just downloading this directory will not run the code as the Git upload is ignoring files that store the API Key.

## Key Findings

**Sentiment-Based Trading Strategy Performance (July-December 2024)**

âœ… **+14.95% Raw Total Return** (weekly value-weighted long-short strategy over 6 months, 32.73% annualized)  
âœ… **+35.48% Gross Alpha** (Fama-French 5-Factor model, annualized)  
âœ… **+27.27% Net Alpha** after realistic transaction costs (20 bps per round-trip)  
âœ… **t=3.50*** Cross-Sectional Significance (Fama-MacBeth monthly, p<0.01)  
âœ… **Factor Exposures**: Negative market beta (-0.82), strong profitability/investment tilts (-0.80, -0.86), Low RÂ² (28%)  
âœ… **Asymmetric Signal Power**: Short leg drives performance (-38.70% alpha vs +1.82% long)  

**Strategic Insights:**
- Weekly rebalancing + value-weighting essential for capturing sentiment signal
- Signal excels at identifying overvalued stocks (strong short leg performance)
- Alpha survives even at high transaction costs (50 bps â†’ +14.94% net alpha)
- Cross-sectional validation confirms time-series factor model results

---

## Directory Structure (updated version - Complete_File-Structure.md)

```
group_{15}/
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .env                              â† API key (not tracked in git)
â”œâ”€â”€ requirements.txt                  â† Python dependencies
â”œâ”€â”€ README.md
â”œâ”€â”€ Can ChatGPT Forecast Stock Price Movements.pdf  â† Reference paper
â”‚
â”œâ”€â”€ Documentations/                   â† Project documentation
â”‚   â”œâ”€â”€ Analysis Planning (Now-Redundant).md  â† Project planning notes
â”‚   â”œâ”€â”€ Criticisms.md                 â† Critical analysis and limitations
â”‚   â”œâ”€â”€ Data Cleaning Methodology.md  â† Detailed data cleaning documentation
â”‚   â”œâ”€â”€ Used_Statistics(Prompt Engineering).md  â† Statistical methods documentation
â”‚   â”œâ”€â”€ Factoring Notes.md            â† Factor model analysis notes
â”‚   â”œâ”€â”€ Fama_Macbeth Notes.md         â† Cross-sectional analysis notes
â”‚   â”œâ”€â”€ Long-Short Notes.md           â† Long-short strategy notes
â”‚   â”œâ”€â”€ walkthrough.md                â† Step-by-step project guide
â”‚   â””â”€â”€ Final Summaries/              â† Comprehensive reports
â”‚       â”œâ”€â”€ Executive_Summary.md      â† Full analysis report (50+ pages)
â”‚       â”œâ”€â”€ Presentation_Slides.md    â† Presentation deck (15 slides)
â”‚       â””â”€â”€ Summarized_Results_Table.md â† Results summary table
â”‚
â”œâ”€â”€ All_RAW_Returns/                  â† Raw sentiment and return data
â”‚   â”œâ”€â”€ sentiments_group 15.csv       â† Raw sentiment data (gitignored, 310MB)
â”‚   â””â”€â”€ Extracted Files/              â† Cleaned sentiment extractions
â”‚       â””â”€â”€ Final Extracted File.csv  â† Validated, sorted sentiment data
â”‚
â”œâ”€â”€ data/                             â† Cleaned and processed data
â”‚   â”œâ”€â”€ data.ipynb                    â† Data exploration and analysis
â”‚   â”œâ”€â”€ daily_return_data_cleaned.csv â† Cleaned returns sorted by ticker+date
â”‚   â”œâ”€â”€ signal_return_panel_cleaned(2).csv â† Final cleaned panel
â”‚   â”œâ”€â”€ Full Extracted File (sorted).csv â† Sorted sentiment data
â”‚   â”œâ”€â”€ Fama_French/                  â† Fama-French factor data
â”‚   â”‚   â”œâ”€â”€ F-F_Research_Data_Factors_daily.csv
â”‚   â”‚   â”œâ”€â”€ F-F_Research_Data_5_Factors_2x3_daily.csv
â”‚   â””â”€â”€ â””â”€â”€ ... (monthly versions)
â”‚
â”œâ”€â”€ Prompt References/                â† Reference papers and prompting ideas
â”‚   â”œâ”€â”€ Prompting Idea Notes.txt      â† Prompting strategy notes
â”‚   â”œâ”€â”€ Game-on Social networks and markets.pdf
â”‚   â””â”€â”€ Understanding Heterogeneity of Investor Sentiment on Social media.pdf
â”‚
â”œâ”€â”€ prompts/                          â† Prompt engineering versions
â”‚   â”œâ”€â”€ prompt_v1.txt
â”‚   â”œâ”€â”€ prompt_v2.txt
â”‚   â”œâ”€â”€ prompt_v3.txt
â”‚   â”œâ”€â”€ prompt_v4.txt                 â† Persona-based with MEME/NORMAL regime
â”‚   â”œâ”€â”€ prompt_v5.txt                 â† Improved v4 with balanced examples
â”‚   â”œâ”€â”€ prompt_v5(only_score_reason).txt  â† Clean output format (no intermediate reasoning)
â”‚   â”œâ”€â”€ prompt_v5(without_Regime).txt     â† Equal weights, no regime detection
â”‚   â”œâ”€â”€ prompt_v6.txt                 â† Includes tags for article context
â”‚   â”œâ”€â”€ prompt_v7.txt                 â† Further refined version
â”‚   â”œâ”€â”€ prompt_v8 (FINAL).txt         â† Final optimized prompt version
â”‚   â”œâ”€â”€ prompt_ziheng.txt
â”‚   â””â”€â”€ prompt_ziheng_formatted.txt
â”‚
â”œâ”€â”€ src/                              â† Source code
â”‚   â”œâ”€â”€ api_client.py                 â† Groq API client + call logic
â”‚   â”œâ”€â”€ prompt_engine.py              â† Loads prompts + builds messages (supports tags)
â”‚   â”œâ”€â”€ sentiment_analysis.py         â† Flexible parser (persona + simple formats)
â”‚   â”œâ”€â”€ run_analysis.py               â† Main pipeline runner (sentiment scoring)
â”‚   â”‚
â”‚   â”œâ”€â”€ Modeling and Analysis/        â† Data processing and statistical analysis scripts
â”‚   â”‚   â”œâ”€â”€ Extract_Data.py           â† Parses sentiment text, validates tickers, calculates scores
â”‚   â”‚   â”œâ”€â”€ data_cleanup_returns.py   â† Filters returns by sentiment tickers, sorts by ticker+date
â”‚   â”‚   â”œâ”€â”€ prepare_signal_return_panel.py â† Creates signal-return panel structure
â”‚   â”‚   â”œâ”€â”€ clean_signal_return_panel.py  â† Cleans panel data
â”‚   â”‚   â”œâ”€â”€ validate_signal_return_panel.py â† Data validation checks
â”‚   â”‚   â”œâ”€â”€ portfolio_backtest.py     â† Portfolio construction and backtesting engine
â”‚   â”‚   â”œâ”€â”€ factor_alpha.py           â† Factor model analysis (CAPM/FF3/FF5) with interpretations
â”‚   â”‚   â”œâ”€â”€ transaction_cost_analysis.py  â† Net alpha after transaction costs (10/20/50 bps)
â”‚   â”‚   â”œâ”€â”€ fama_macbeth.py           â† Cross-sectional predictability tests
â”‚   â”‚   â””â”€â”€ create_visualizations.py  â† Comprehensive visualization suite (24 charts)
â”‚   â”‚
â”‚   â””â”€â”€ Prompt Comparison/            â† Prompt performance comparison utilities
â”‚       â”œâ”€â”€ merge_data.py             â† Merges daily decision scores with returns (+1 day)
â”‚       â”œâ”€â”€ merge_data_monthly.py     â† Merges monthly averaged scores with returns (+1 month)
â”‚       â”œâ”€â”€ average_monthly_scores.py â† Averages daily scores by ticker and month
â”‚       â”œâ”€â”€ plot_data.py              â† Generates daily correlation plots (4-panel)
â”‚       â”œâ”€â”€ plot_data_monthly.py      â† Generates monthly correlation plots (4-panel)
â”‚       â””â”€â”€ aggregate_analysis.py     â† Aggregate statistics across prompt versions
â”‚
â”œâ”€â”€ Statistics/                       â† Statistical analysis outputs and portfolio returns
â”‚   â”œâ”€â”€ Factor_Models Statistics/     â† Factor model analysis outputs
â”‚   â”‚   â”œâ”€â”€ alpha_full_results.csv    â† All 36 regressions (4 configs Ã— 3 portfolios Ã— 3 models)
â”‚   â”‚   â”œâ”€â”€ alpha_summary.csv         â† Summary table with significance stars
â”‚   â”‚   â”œâ”€â”€ net_alpha_after_costs.csv â† Net alpha at different cost scenarios
â”‚   â”‚   â””â”€â”€ net_alpha_summary_table.csv â† Cost analysis summary
â”‚   â”‚
â”‚   â”œâ”€â”€ Fama_MacBeth Statistics/      â† Cross-sectional analysis outputs
â”‚   â”‚   â”œâ”€â”€ fmb_slopes_monthly.csv    â† Monthly cross-sectional slopes (6 periods)
â”‚   â”‚   â”œâ”€â”€ fmb_slopes_weekly.csv     â† Weekly cross-sectional slopes (27 periods)
â”‚   â”‚   â””â”€â”€ fmb_summary.csv           â† Summary statistics (mean slopes, t-stats, p-values)
â”‚   â”‚
â”‚   â”œâ”€â”€ Portfolio Returns/            â† Portfolio backtesting and analysis
â”‚   â”‚   â”œâ”€â”€ Analysis_Notes.md         â† Portfolio analysis documentation
â”‚   â”‚   â”œâ”€â”€ portfolio_comparison_all_configs.csv â† Configuration comparison results
â”‚   â”‚   â”œâ”€â”€ portfolio_returns_*.csv   â† Returns by strategy (weekly/monthly, equal/value)
â”‚   â”‚   â””â”€â”€ portfolio_summary_*.csv   â† Performance summaries by strategy
â”‚   â”‚
â”‚   â””â”€â”€ Prompt Testing Phase/         â† Prompt evaluation results
â”‚       â”œâ”€â”€ Decision Testing Scores (Prompt Testing)/  â† Raw sentiment scoring results
â”‚       â”œâ”€â”€ Merged Data (Test Data - Prompt Evaluation)/  â† Merged test datasets
â”‚       â””â”€â”€ Score Statistics Used For Prompt Evaluation/  â† Statistical summaries for prompt comparison
â”‚
â”œâ”€â”€ Figures and Tables/               â† Visualizations and plots
â”‚   â”œâ”€â”€ Figures/                      â† Publication-quality visualizations (300 DPI PNG)
â”‚   â”‚   â”œâ”€â”€ Figure Summaries (Explained).pdf  â† Detailed chart documentation with conclusions
â”‚   â”‚   â”œâ”€â”€ cumulative_returns_*.png  â† Cumulative return charts (4 configs + comparison)
â”‚   â”‚   â”œâ”€â”€ drawdown_*.png            â† Drawdown analysis charts (4 configs)
â”‚   â”‚   â”œâ”€â”€ rolling_sharpe_*.png      â† Rolling Sharpe ratio charts (4 configs)
â”‚   â”‚   â”œâ”€â”€ performance_summary.png   â† Multi-panel performance dashboard
â”‚   â”‚   â”œâ”€â”€ alpha_comparison.png      â† Alpha across CAPM/FF3/FF5 models
â”‚   â”‚   â”œâ”€â”€ r_squared_comparison.png  â† Model explanatory power
â”‚   â”‚   â”œâ”€â”€ factor_exposures.png      â† Factor betas (Market/SMB/HML/RMW/CMA)
â”‚   â”‚   â”œâ”€â”€ gross_vs_net_alpha.png    â† Transaction cost impact
â”‚   â”‚   â”œâ”€â”€ fama_macbeth_*.png        â† Fama-MacBeth analysis charts (5 total)
â”‚   â”‚   â”œâ”€â”€ results_dashboard.png     â† Comprehensive 6-panel results dashboard
â”‚   â”‚   â”œâ”€â”€ Panel_validation.png      â† Panel data validation visualization
â”‚   â”‚   â”œâ”€â”€ Used Figures In Report/   â† Figures selected for final report
â”‚   â”‚   â””â”€â”€ Unused Figures/           â† Alternative visualizations not used
â”‚   â”‚
â”‚   â””â”€â”€ Plots Used For Prompt Evaluation/  â† Prompt comparison visualizations
â”‚       â”œâ”€â”€ plots_v6/                 â† Daily plots per ticker (v6)
â”‚       â”œâ”€â”€ plots_monthly_v6/         â† Monthly plots per ticker (v6)
â”‚       â”œâ”€â”€ plots_v5_without_Regime/  â† Plots for v5 without regime detection
â”‚       â”œâ”€â”€ plots_v6_FullData_adjusted/  â† Full dataset plots with time adjustment
â”‚       â”œâ”€â”€ plots_v6_FullData_non-adjusted/  â† Full dataset plots without adjustment
â”‚       â”œâ”€â”€ plots_Ziheng/             â† Ziheng prompt version plots
â”‚       â””â”€â”€ Aggregate Analysis/       â† Aggregate statistics across prompt versions
â”‚
â””â”€â”€ venv/                             â† Virtual environment (not tracked in git)
```

## Key Components

### Data Cleaning and Extraction

#### **Extract_Data.py** (src/Modeling and Analysis/)
- Comprehensive sentiment data extraction and validation pipeline
- Comprehensive sentiment data extraction and validation pipeline
- **Regex-Based Extraction**: Parses unstructured sentiment text using pattern matching for:
  - Headlines (with/without quotes)
  - Investor perspective scores: NOVICE, FANATIC, DAY/SWING, LONG-TERM
  - Market regime classification (MEME/NORMAL)
  - Ticker symbols embedded in sentiment text
  - Pre-calculated FINAL_WEIGHTED scores for validation
- **Sentiment Score Calculation**: 
  - NORMAL regime: `0.20Ã—NOVICE + 0.10Ã—FANATIC + 0.30Ã—DAY/SWING + 0.40Ã—LONG-TERM`
  - MEME regime: `0.40Ã—NOVICE + 0.20Ã—FANATIC + 0.30Ã—DAY/SWING + 0.10Ã—LONG-TERM`
- **Data Quality Validation**:
  - Stage 1: Filters rows with missing required fields (date, ticker, scores, regime)
  - Stage 2: Cross-validates ticker consistency (original vs extracted from sentiment)
  - Removes ~1,272 records with ticker mismatches
  - Standardizes all scores to 6 decimal places
- **Output**: Cleaned CSV with validation columns (Ticker(in_sentiment), Final_Weighted) for comparison
- See [Documentations/Data_Cleaning_Methodology.md](Documentations/Data_Cleaning_Methodology.md) for detailed documentation

#### **data_analysis.ipynb** (All_RAW_Returns/)
- Interactive quality assurance notebook for post-extraction validation
- **Ticker Consistency Analysis**: Identifies mismatches between original and extracted tickers
- **Score Validation**: Compares calculated Sentiment_Score vs extracted Final_Weighted (tolerance: 0.000001)
- Provides detailed reporting on data quality issues with row-level diagnostics

#### **data_cleanup_returns.py** (src/Modeling and Analysis/)
- Cleans daily return data to match sentiment dataset scope
- **Ticker Filtering**: Retains only tickers present in sentiment analysis
- **Date Cleaning**: Removes timestamps, standardizes to YYYY-MM-DD format
- **Sorting**: Orders data by TICKER (alphabetically), then by date (chronologically)
- Provides detailed statistics on records removed and date ranges
- Input: daily_return_data_datefiltered.csv + Final Extracted File.csv
- Output: daily_return_data_cleaned.csv (sorted and filtered)

#### **portfolio_backtest.py** (src/Modeling and Analysis/)
- Core portfolio construction and backtesting engine for sentiment-based trading strategies
- **Strategy Configurations**: Tests 4 different strategy setups:
  - **Monthly Equal-Weighted**: Monthly rebalancing with equal position sizes
  - **Monthly Value-Weighted**: Monthly rebalancing with market-cap weighted positions
  - **Weekly Equal-Weighted**: Weekly rebalancing with equal position sizes
  - **Weekly Value-Weighted**: Weekly rebalancing with market-cap weighted positions
- **Portfolio Construction**:
  - Long portfolio: Top quintile (20% highest sentiment scores)
  - Short portfolio: Bottom quintile (20% lowest sentiment scores)
  - Long-Short: Combined long and short positions
- **Performance Metrics**: Calculates returns, volatility, Sharpe ratio, max drawdown for each strategy
- **Key Features**:
  - Handles missing data and edge cases robustly
  - Accounts for realistic rebalancing constraints
  - Generates detailed performance summaries and comparison tables
- **Output Files** (saved to `Statistics/Portfolio Returns/`):
  - `portfolio_returns_[frequency]_[weighting].csv`: Daily return series for Long/Short/Long-Short
  - `portfolio_summary_[frequency]_[weighting].csv`: Performance statistics summary
  - `portfolio_comparison_all_configs.csv`: Side-by-side comparison of all 4 configurations
- **Usage**: Run after data cleaning to generate portfolio returns needed for factor model analysis

### Factor Model Analysis & Statistical Validation

#### **factor_alpha.py** (src/Modeling and Analysis/)
- Comprehensive factor model analysis with Newey-West HAC standard errors
- Comprehensive factor model analysis with Newey-West HAC standard errors
- **Models Tested**: CAPM, Fama-French 3-Factor (FF3), Fama-French 5-Factor (FF5)
- **Key Features**:
  - Runs 36 regressions: 4 configurations Ã— 3 portfolios (Long/Short/Long-Short) Ã— 3 models
  - Newey-West SE with 10 lags for daily data (accounts for autocorrelation and heteroskedasticity)
  - Alpha significance testing with t-statistics and p-values
  - Comprehensive interpretations with 8 analysis sections per strategy:
    - Î± Alpha analysis (magnitude, direction, significance)
    - ðŸ“Š Model comparison (RÂ² improvements across CAPM/FF3/FF5)
    - ðŸ“ˆ Alpha stability checks (consistency across specifications)
    - ðŸ§¬ Factor exposures (beta interpretation for all factors)
    - âš–ï¸ Long/short leg breakdown (identifies performance drivers)
    - ðŸ’¡ Strategy insights (rebalancing frequency, weighting effects)
    - ðŸŽ¯ Overall assessment with star ratings
- **Output Files**:
  - `Statistics/Factor_Models Statistics/alpha_full_results.csv`: Detailed regression results (all 36 regressions)
  - `Statistics/Factor_Models Statistics/alpha_summary.csv`: Summary table with significance stars (*** p<0.01, ** p<0.05, * p<0.10)
- **Key Results**: Weekly value-weighted long-short shows +35.48% alpha (FF5), driven primarily by short leg (-38.70% alpha)

#### **transaction_cost_analysis.py** (src/Modeling and Analysis/)
- Validates economic viability of strategies after implementation costs
- **Cost Scenarios**:
  - Low (10 bps): Institutional investors with high liquidity
  - Base (20 bps): Realistic case for most investors
  - High (50 bps): Retail investors or low liquidity
- **Calculation**: Annual cost = Turnover Ã— Cost per trade Ã— Rebalancing frequency
- **Output Files**:
  - `Statistics/Factor_Models Statistics/net_alpha_after_costs.csv`: Net alpha under all cost scenarios
  - `Statistics/Factor_Models Statistics/net_alpha_summary_table.csv`: Summary comparison table
- **Key Results**: Weekly value-weighted survives with +27.27% net alpha after 20 bps costs (gross alpha +35.48%, costs -8.21%)

#### **fama_macbeth.py** (src/Modeling and Analysis/)
- Cross-sectional predictability tests validating signal from different angle
- **Methodology**: 
  - For each period t, run cross-sectional regression: R_{i,t+1} = a_t + b_t Ã— Signal_{i,t}
  - Collect time-series of slopes {b_1, b_2, ..., b_T}
  - Test if mean(b_t) â‰  0 using Newey-West standard errors
- **Interpretations**:
  - Positive mean slope â†’ higher sentiment predicts higher returns
  - Statistical significance (t>1.96) â†’ systematic predictive power
  - Economic magnitude â†’ 1-unit signal increase implies b% return change
- **Output Files**:
  - `Statistics/Fama_MacBeth Statistics/fmb_slopes_monthly.csv`: 6 monthly cross-sectional slopes
  - `Statistics/Fama_MacBeth Statistics/fmb_slopes_weekly.csv`: 27 weekly cross-sectional slopes
  - `Statistics/Fama_MacBeth Statistics/fmb_summary.csv`: Mean slopes, t-statistics, p-values, significance
- **Key Results**: Highly significant predictive power (Monthly: t=3.50***, p=0.005; Weekly: t=2.87***, p=0.008)

#### **create_visualizations.py** (src/Modeling and Analysis/)
- Generates 24 publication-quality charts (300 DPI PNG) for report and presentation
- **Portfolio Performance Charts** (14 charts):
  - Cumulative returns for each config (Long/Short/Long-Short lines)
  - Comparison of all long-short strategies
  - Drawdown analysis (peak-to-trough declines)
  - Rolling Sharpe ratios (20-day window)
  - Multi-panel performance summary (returns, Sharpe, volatility, drawdown)
- **Factor Model Charts** (4 charts):
  - Alpha comparison across CAPM/FF3/FF5
  - RÂ² comparison showing model fit
  - Factor exposures (betas for Market/SMB/HML/RMW/CMA)
  - Gross vs net alpha after transaction costs
- **Fama-MacBeth Charts** (5 charts):
  - Time-series of monthly/weekly slopes with t-statistics
  - Distribution histograms of slopes
  - Comparison of mean slopes and significance across frequencies
- **Dashboard** (1 chart):
  - Comprehensive 6-panel results dashboard integrating all key findings
- **Output**: All 24 charts saved to `Figures and Tables/Figures/` with detailed documentation in `Figure Summaries (Explained).pdf`
- **Styling**: Professional color schemes (green/red/blue for long/short/long-short, orange/purple/teal for CAPM/FF3/FF5)

### Sentiment Analysis Pipeline

#### **api_client.py**
- Manages communication with the Groq API for LLM-based sentiment analysis
- Handles API key loading from environment variables
- Implements error handling and retry logic for API calls
- Returns raw LLM responses to be parsed by sentiment_analysis.py

#### **prompt_engine.py**
- Loads prompt templates from the `prompts/` directory
- Builds structured message payloads for the LLM (system + user messages)
- Supports optional `tags` parameter to include article context/topics
- Enables easy switching between different prompt versions without code changes

#### **sentiment_analysis.py**
- Flexible parser that supports multiple LLM response formats:
  - **Persona-based format**: Extracts NOVICE, FANATIC, DAY/SWING, LONG-TERM scores, detects MEME vs NORMAL regime, calculates weighted score in Python
  - **Simple format**: Extracts "Line 1:" score directly
  - **Fallback parsing**: Handles responses missing labels by detecting standalone numbers + text
- Returns tuple of (score, reason) for each headline
- Critical for handling different prompt versions (v4/v5/v6/v7/v8 and ziheng variants)
- Designed to be robust across prompt evolution without code changes

#### **run_analysis.py**
- Main entry point for sentiment analysis pipeline
- Reads input CSV with columns: ID_Number, Ticker, Date, Headline, (optional) tags
- Processes each headline through the Groq API using selected prompt
- Extracts date-only format (splits on 'T' to remove timestamps)
- Outputs CSV with: ID_Number, Ticker, Date, Headline, Score, Reason
- Usage: Configure prompt file path and input/output CSV paths at bottom of script

### Prompt Engineering Evolution

The project includes multiple prompt versions (v1-v8), each iterating on the approach to sentiment analysis:

- **prompt_v1.txt - v3.txt**: Initial experiments with different prompting strategies
- **prompt_v4.txt**: Major breakthrough - introduced persona-based scoring (NOVICE, FANATIC, DAY/SWING, LONG-TERM) with MEME/NORMAL regime detection
- **prompt_v5.txt**: Refined v4 with balanced examples and improved instructions
  - **prompt_v5(only_score_reason).txt**: Streamlined output format removing intermediate reasoning steps
  - **prompt_v5(without_Regime).txt**: Equal-weighted version without regime detection for comparison
- **prompt_v6.txt**: Added support for article tags/context to improve sentiment accuracy
- **prompt_v7.txt**: Further refinements to scoring criteria and example quality
- **prompt_v8 (FINAL).txt**: Final optimized version incorporating all learnings - recommended for production use
- **prompt_ziheng.txt / prompt_ziheng_formatted.txt**: Alternative approach by team member with different scoring methodology

**Recommendation**: Use `prompt_v8 (FINAL).txt` for new analyses as it represents the most refined and tested version.

### Data Processing

#### **merge_data.py** (src/Prompt Comparison/)
- Combines daily sentiment scores with daily return data
- **Key feature**: Adds +1 day to decision dates before merging
  - Rationale: Returns are measured after the headline, not same-day
  - Uses `timedelta(days=1)` for date adjustment
- Performs inner join on Ticker and adjusted Date
- Input: Decision_Testing files + data/data (sample and setup)/Daily_Return_Matching_PTD_1.csv
- Output: Merged_Data_v6.csv with both Score and RET columns

#### **average_monthly_scores.py** (src/Prompt Comparison/)
- Aggregates daily sentiment scores into monthly averages per ticker
- Groups data by `['Ticker', 'YearMonth']` where YearMonth = date.to_period('M')
- Calculates mean of Score and RET for each ticker-month combination
- Rounds values to 3 decimal places for consistency
- Input: Merged daily data (e.g., Merged_Data_v6.csv)
- Output: Monthly_Averaged_Score_v6.csv with Date in YYYY-MM format

#### **merge_data_monthly.py** (src/Prompt Comparison/)
- Combines monthly averaged scores with monthly return data
- **Key feature**: Adds +1 month to decision dates before merging
  - Rationale: Monthly returns are measured the month after the sentiment period
  - Uses `DateOffset(months=1)` for month arithmetic
- Handles YYYY-MM date format (month-level precision)
- Uses `suffixes=('_daily', '_monthly')` to differentiate RET columns if both datasets have RET
- Input: Monthly_Averaged_Score_v6.csv + Monthly_Return_Data_sample.csv
- Output: Merged_Monthly_Data_v6.csv with Score and RET columns

### Visualization

#### **plot_data.py** (src/Prompt Comparison/)
- Generates comprehensive 4-panel visualizations for daily data per ticker:
  1. **Raw Values (dual y-axis)**: Score and RET over time with different scales
  2. **Z-Score Normalized**: Both metrics standardized for direct comparison
  3. **Scatter Plot**: Score vs RET with Pearson correlation coefficient and trend line
  4. **Rolling 5-Day Correlation**: Time-series showing how correlation evolves
- Exports statistical summary CSV with correlations, means, std devs per ticker
- Saves plots to `Figures and Tables/Plots Used For Prompt Evaluation/plots_v6/` directory
- Usage: Configure input CSV path and version number in script

#### **plot_data_monthly.py** (src/Prompt Comparison/)
- Same 4-panel structure as plot_data.py, adapted for monthly data:
  - Uses 'RET (monthly)' column instead of 'RET'
  - Rolling window reduced to 3 months (from 5 days)
  - YYYY-MM date formatting on x-axis
  - Larger scatter plot markers (fewer data points)
- Exports Monthly_Plot_Statistics_v6.csv with monthly correlations
- Saves plots to `Figures and Tables/Plots Used For Prompt Evaluation/plots_monthly_v6/` directory
- Handles lower data density typical of monthly aggregations

## Process Workflows

### Statistical Validation and Analysis Workflow (Factor Models & Cross-Sectional Tests)

1. **Prepare Portfolio Returns**
   - Ensure portfolio return files are in place:
     - `Statistics/Portfolio Returns/portfolio_returns_monthly_equal.csv`
     - `Statistics/Portfolio Returns/portfolio_returns_monthly_value.csv`
     - `Statistics/Portfolio Returns/portfolio_returns_weekly_equal.csv`
     - `Statistics/Portfolio Returns/portfolio_returns_weekly_value.csv`
   - Each file should contain daily returns with columns: date, Long, Short, Long_Short

2. **Prepare Fama-French Factor Data**
   - Download from Kenneth French Data Library: https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html
   - Required files in `data/Fama_French/`:
     - `F-F_Research_Data_Factors_daily.csv` (Market, SMB, HML, RF)
     - `F-F_Research_Data_5_Factors_2x3_daily.csv` (adds RMW, CMA)
     - Monthly versions if needed
   - Format: Date in YYYYMMDD format, factors as percentages

3. **Run Factor Model Analysis**
   ```
   python group_{15}/src/Modeling\ and\ Analysis/factor_alpha.py
   ```
   - **What it does**:
     - Loads 4 portfolio configurations and Fama-French factors
     - Runs 36 regressions (4 configs Ã— 3 portfolios Ã— 3 models)
     - Calculates alpha with Newey-West standard errors (10 lags)
     - Provides comprehensive interpretations (8 sections per strategy)
   - **Outputs**:
     - Console: Detailed interpretations with Unicode formatting (Î±, Î², RÂ², â˜… ratings)
     - `Statistics/Factor_Models Statistics/alpha_full_results.csv`: All regression coefficients, t-stats, p-values
     - `Statistics/Factor_Models Statistics/alpha_summary.csv`: Clean summary table with significance stars
   - **Key Metrics**: Alpha, t-statistics, p-values, RÂ², factor betas (Market/SMB/HML/RMW/CMA)

4. **Run Transaction Cost Analysis**
   ```
   python group_{15}/src/Modeling\ and\ Analysis/transaction_cost_analysis.py
   ```
   - **What it does**:
     - Takes gross alpha from factor models
     - Calculates annual transaction costs: Turnover Ã— Cost Ã— Rebalancing frequency
     - Tests 3 scenarios: 10 bps (low), 20 bps (base), 50 bps (high)
     - Computes net alpha = gross alpha - costs
   - **Outputs**:
     - Console: Net alpha tables for each cost scenario
     - `Statistics/Factor_Models Statistics/net_alpha_after_costs.csv`: Net alpha under all scenarios
     - `Statistics/Factor_Models Statistics/net_alpha_summary_table.csv`: Summary comparison
   - **Key Finding**: Weekly value-weighted survives with +27.27% net alpha (20 bps costs)

5. **Run Fama-MacBeth Cross-Sectional Analysis**
   ```
   python group_{15}/src/Modeling\ and\ Analysis/fama_macbeth.py
   ```
   - **What it does**:
     - Loads signal-return panel data
     - Assigns rebalancing periods (monthly/weekly)
     - Runs cross-sectional regressions for each period
     - Computes mean slopes and Newey-West t-statistics
   - **Input**: `data/signal_return_panel_cleaned(2).csv`
   - **Outputs**:
     - Console: Summary statistics with t-stats and significance
     - `Statistics/Fama_MacBeth Statistics/fmb_slopes_monthly.csv`: 6 monthly slopes
     - `Statistics/Fama_MacBeth Statistics/fmb_slopes_weekly.csv`: 27 weekly slopes
     - `Statistics/Fama_MacBeth Statistics/fmb_summary.csv`: Mean slopes, t-stats, p-values
   - **Key Results**: Monthly t=3.50***, Weekly t=2.87*** (both highly significant)

6. **Generate Comprehensive Visualizations**
   ```
   [Console]::OutputEncoding = [System.Text.Encoding]::UTF8
   $env:PYTHONIOENCODING="utf-8"
   python group_{15}/src/Modeling\ and\ Analysis/create_visualizations.py
   ```
   - **Prerequisites**: Install visualization libraries if needed:
     ```
     pip install matplotlib seaborn
     ```
   - **What it does**:
     - Creates 24 high-resolution charts (300 DPI PNG)
     - Portfolio performance: cumulative returns, drawdowns, rolling Sharpe, summary
     - Factor models: alpha comparison, RÂ², factor exposures, gross vs net alpha
     - Fama-MacBeth: slope time-series, distributions, comparisons
     - Dashboard: 6-panel comprehensive overview
   - **Outputs**: All 24 charts saved to `Figures and Tables/Figures/`
   - **Note**: Windows PowerShell requires UTF-8 encoding for proper Unicode display

7. **Review Documentation**
   - **Chart Documentation**: `Figures and Tables/Figures/Figure Summaries (Explained).pdf`
     - Detailed descriptions of all 24 charts
     - Metric definitions and interpretations
     - 2-3 sentence conclusions per chart
   - **Comprehensive Report**: `Documentations/Final Summaries/Executive_Summary.md` (50+ pages)
     - Full methodology, results, discussion, conclusions
     - All tables, statistics, and interpretations
   - **Presentation**: `Documentations/Final Summaries/Presentation_Slides.md` (15 slides)
     - Slide-by-slide content with speaker notes
     - Chart references and timing guidelines
     - Q&A preparation with common questions

### Data Cleaning and Preparation Workflow

1. **Raw Sentiment Extraction**
   ```
   python group_{15}/src/Modeling\ and\ Analysis/Extract_Data.py
   ```
   - Input: `sentiments_group 15.csv` (raw unstructured sentiment text)
   - Process:
     - Extracts headlines, investor scores, regime, ticker, and FINAL_WEIGHTED using regex
     - Calculates Sentiment_Score using regime-specific weighted formulas
     - Validates ticker consistency (removes ~1,272 mismatches, ~7.5% of data)
     - Filters rows with missing critical fields
     - Standardizes all scores to 6 decimal places
   - Output: `All_RAW_Returns/Extracted Files/Final Extracted File.csv`
   - Statistics: Reports rows removed due to missing data and ticker mismatches

2. **Quality Assurance Validation** (optional but recommended)
   - Open `All_RAW_Returns/data_analysis.ipynb` in Jupyter
   - Run comparison cells to verify:
     - Ticker consistency between original and extracted values
     - Sentiment_Score matches Final_Weighted (within floating-point tolerance)
   - Review any flagged discrepancies before proceeding

3. **Return Data Cleaning**
   ```
   python group_{15}/src/Modeling\ and\ Analysis/data_cleanup_returns.py
   ```
   - Input: 
     - `data/daily_return_data_datefiltered.csv` (returns for all tickers)
     - `All_RAW_Returns/Extracted Files/Final Extracted File.csv` (validated sentiments)
   - Process:
     - Filters returns to only include tickers with sentiment data
     - Removes timestamps from dates (standardizes to YYYY-MM-DD)
     - **Sorts by TICKER (alphabetically), then by date (chronologically)**
   - Output: `data/daily_return_data_cleaned.csv`
   - Statistics: Reports tickers and records removed, date ranges

4. **Panel Data Preparation** (optional, for advanced analysis)
   ```
   python group_{15}/src/Modeling\ and\ Analysis/prepare_signal_return_panel.py
   ```
   - Combines sentiment signals with return data in panel format
   - Output: `data/signal_return_panel.csv`

### Daily Sentiment-Return Analysis Workflow

1. **Sentiment Scoring**
   ```
   python src/run_analysis.py
   ```
   - Input: CSV with headlines (ID_Number, Ticker, Date, Headline, [tags])
   - Process: Sends each headline to Groq API using selected prompt template
   - **Note**: Configure prompt path in script - use `prompts/prompt_v8 (FINAL).txt` for production analyses
   - Output: `Statistics/Prompt Testing Phase/Decision Testing Scores (Prompt Testing)/Decision_Testing*.csv` (adds Score, Reason columns)

2. **Data Preparation**
   - Extract appropriate date range from `train_df.csv` or equivalent dataset
   - Ensure dates are in YYYY-MM-DD format (use `.dt.strftime('%Y-%m-%d')` if needed)
   - Filter for desired year range (e.g., 2020-2021)

3. **Merge with Returns Data**
   ```
   python src/Prompt\ Comparison/merge_data.py
   ```
   - Input: Decision_Testing*.csv + data/data (sample and setup)/Daily_Return_Matching_PTD_1.csv
   - Process: **Adds +1 day** to sentiment dates, then joins on Ticker and adjusted Date
   - Rationale: Stock returns are measured the day AFTER the headline publication
   - Output: `Statistics/Prompt Testing Phase/Merged Data (Test Data - Prompt Evaluation)/Merged_Data_v6.csv` (Score + RET columns aligned)

4. **Generate Visualizations**
   ```
   python src/Prompt\ Comparison/plot_data.py
   ```
   - Input: Merged_Data_v6.csv
   - Process: Creates 4-panel plots per ticker (raw, normalized, scatter, rolling correlation)
   - Output: 
     - Plots: `Figures and Tables/Plots Used For Prompt Evaluation/plots_v6/[TICKER]_v6.png`
     - Stats: `Statistics/Prompt Testing Phase/Score Statistics Used For Prompt Evaluation/Plot_Statistics_v6.csv`

5. **Manual Analysis** (if needed)
   - Open `Plot_Statistics_v6.csv` in Excel or pandas
   - Calculate portfolio-wide averages of correlation coefficients
   - Identify tickers with strongest sentiment-return relationships
   - Compare different prompt versions by analyzing separate stats files

### Monthly Sentiment-Return Analysis Workflow

1. **Sentiment Scoring** (same as daily)
   ```
   python src/run_analysis.py
   ```
   - Output: Daily-level sentiment scores

2. **Aggregate to Monthly Averages**
   ```
   python src/Prompt\ Comparison/average_monthly_scores.py
   ```
   - Input: `Statistics/Prompt Testing Phase/Merged Data (Test Data - Prompt Evaluation)/Merged_Data_v6.csv` (or direct from Decision_Testing if merging not yet done)
   - Process: Groups by Ticker and YearMonth, calculates mean Score and RET
   - Output: `Statistics/Prompt Testing Phase/Merged Data (Test Data - Prompt Evaluation)/Monthly_Averaged_Score_v6.csv` (dates in YYYY-MM format)

3. **Data Preparation**
   - Extract monthly return data from `train_return_data.csv` or equivalent
   - Ensure dates are in YYYY-MM format (use `.dt.strftime('%Y-%m')` after datetime conversion)
   - Filter for desired year range

4. **Merge with Monthly Returns**
   ```
   python src/Prompt\ Comparison/merge_data_monthly.py
   ```
   - Input: Monthly_Averaged_Score_v6.csv + data/data (sample and setup)/Monthly_Return_Data_sample.csv
   - Process: **Adds +1 month** to sentiment dates, then joins on Ticker and adjusted Date
   - Rationale: Monthly returns are measured the month AFTER the sentiment aggregation period
   - Output: `Statistics/Prompt Testing Phase/Merged Data (Test Data - Prompt Evaluation)/Merged_Monthly_Data_v6.csv` (Score + RET aligned with time offset)

5. **Generate Monthly Visualizations**
   ```
   python src/Prompt\ Comparison/plot_data_monthly.py
   ```
   - Input: Merged_Monthly_Data_v6.csv
   - Process: Creates 4-panel plots per ticker with 3-month rolling correlation window
   - Output:
     - Plots: `Figures and Tables/Plots Used For Prompt Evaluation/plots_monthly_v6/[TICKER]_monthly_v6.png`
     - Stats: `Statistics/Prompt Testing Phase/Score Statistics Used For Prompt Evaluation/Plot_Statistics_Monthly_v6.csv`

6. **Manual Analysis** (if needed)
   - Open `Plot_Statistics_Monthly_v6.csv`
   - Calculate portfolio-wide monthly correlation averages
   - Compare monthly vs daily correlation patterns
   - Monthly data typically shows stronger, clearer trends due to noise reduction

### Important Notes on Time Adjustments

- **Daily Merge (+1 day)**: `merge_data.py` uses `timedelta(days=1)` because market returns are realized the trading day AFTER news publication. Example: Headline on 2021-06-29 is matched with returns from 2021-06-30.

- **Monthly Merge (+1 month)**: `merge_data_monthly.py` uses `DateOffset(months=1)` because monthly returns are calculated for the month FOLLOWING the sentiment period. Example: June 2021 sentiment (2021-06) is matched with July 2021 returns (2021-07).

- These time offsets are critical for causal analysis - measuring the predictive power of sentiment on future returns rather than just correlation with concurrent price movements.

## Output Files Summary

### Factor Model Outputs (`Statistics/Factor_Models Statistics/`)

**alpha_full_results.csv**
- Complete regression results for all 36 models (4 configs Ã— 3 portfolios Ã— 3 factor models)
- Columns: config, portfolio, model, alpha, alpha_t, alpha_p, R2, plus coefficients/t-stats/p-values for each factor
- Use for: Detailed analysis of factor exposures and model comparisons

**alpha_summary.csv**
- Clean summary table optimized for reporting
- Columns: config, portfolio, model, alpha (annualized %), t-stat, significance stars (*** / ** / *)
- Use for: Quick reference and inclusion in reports/presentations

**net_alpha_after_costs.csv**
- Net alpha under three cost scenarios: 10 bps, 20 bps, 50 bps per round-trip
- Columns: config, portfolio, gross_alpha, turnover, rebal_freq, cost_10bps through cost_50bps, net_alpha_10bps through net_alpha_50bps
- Use for: Economic viability assessment and sensitivity analysis

**net_alpha_summary_table.csv**
- Comparison table showing which strategies survive transaction costs
- Includes: gross alpha, annual costs, net alpha, viable (Yes/No) flag
- Use for: Quick assessment of implementable strategies

### Fama-MacBeth Outputs (`Statistics/Fama_MacBeth Statistics/`)

**fmb_slopes_monthly.csv**
- 6 monthly cross-sectional regression slopes (one per rebalancing period)
- Columns: period, period_start, period_end, slope, t_stat, n_obs
- Use for: Time-series analysis of signal predictive power by month

**fmb_slopes_weekly.csv**
- 27 weekly cross-sectional regression slopes
- Same structure as monthly version
- Use for: Higher frequency analysis of signal effectiveness

**fmb_summary.csv**
- Summary statistics for Fama-MacBeth tests
- Rows: monthly and weekly frequencies
- Columns: frequency, mean_slope, t_statistic, p_value, n_periods, significance
- Use for: Overall assessment of cross-sectional predictability

### Visualization Outputs (`Figures and Tables/Figures/`)

**24 PNG Charts (300 DPI):**

*Portfolio Performance (14 charts):*
- `cumulative_returns_[config].png` (4) - Long/Short/Long-Short lines
- `cumulative_returns_comparison.png` (1) - All long-short strategies
- `drawdown_[config].png` (4) - Peak-to-trough declines
- `rolling_sharpe_[config].png` (4) - 20-day rolling Sharpe ratios
- `performance_summary.png` (1) - 4-panel dashboard

*Factor Models (4 charts):*
- `alpha_comparison.png` - Alpha across CAPM/FF3/FF5
- `r_squared_comparison.png` - Model fit comparison
- `factor_exposures.png` - Betas for 5 factors
- `gross_vs_net_alpha.png` - Transaction cost impact

*Fama-MacBeth (5 charts):*
- `fama_macbeth_slopes_[frequency].png` (2) - Slope time-series with t-stats
- `fama_macbeth_distribution_[frequency].png` (2) - Slope histograms
- `fama_macbeth_comparison.png` (1) - Mean slopes and significance

*Dashboard (1 chart):*
- `results_dashboard.png` - 6-panel comprehensive overview

**Figure Summaries (Explained).pdf**
- Detailed documentation for all 24 charts
- Each chart includes: filename, metric definition, 2-3 sentence conclusion
- Use for: Understanding chart interpretations and writing captions

## Usage

### Quick Start (For Reproducing Factor Model Analysis)

If you want to jump directly to the statistical validation and visualization:

1. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   pip install matplotlib seaborn statsmodels
   ```

2. **Run factor model analysis** (requires portfolio returns in `Statistics/Portfolio Returns/` and Fama-French data in `data/Fama_French/`):
   ```bash
   python group_{15}/src/Modeling\ and\ Analysis/factor_alpha.py
   python group_{15}/src/Modeling\ and\ Analysis/transaction_cost_analysis.py
   python group_{15}/src/Modeling\ and\ Analysis/fama_macbeth.py
   ```

3. **Generate visualizations** (Windows PowerShell):
   ```powershell
   [Console]::OutputEncoding = [System.Text.Encoding]::UTF8
   $env:PYTHONIOENCODING="utf-8"
   python group_{15}/src/Modeling\ and\ Analysis/create_visualizations.py
   ```

4. **Review outputs**:
   - Statistical results: `Statistics/Factor_Models Statistics/` and `Statistics/Fama_MacBeth Statistics/`
   - Charts: `Figures and Tables/Figures/` (24 PNG files)
   - Documentation: `Documentations/Final Summaries/Executive_Summary.md` and `Presentation_Slides.md`

### Full Pipeline (From Raw Data)

1. **Install dependencies**: 
   ```
   pip install -r requirements.txt
   ```

2. **Set up API key** in `.env` file:
   ```
   GROQ_API_KEY=your_api_key_here
   ```

3. **Data Cleaning Workflow** (start here for raw data):
   - Run `Extract_Data.py` to clean sentiment data
   - Run `data_cleanup_returns.py` to clean return data
   - (Optional) Validate in `data_analysis.ipynb`

4. **Analysis Workflows**:
   - **Daily analysis**: Follow "Daily Sentiment-Return Analysis Workflow" steps
   - **Monthly analysis**: Follow "Monthly Sentiment-Return Analysis Workflow" steps
   - **Factor models & validation**: Follow "Statistical Validation and Analysis Workflow" steps (NEW)

5. **Review outputs**:
   - Sentiment correlation statistics: `Statistics/Prompt Testing Phase/Score Statistics Used For Prompt Evaluation/`
   - Sentiment correlation plots: `Figures and Tables/Plots Used For Prompt Evaluation/`
   - Portfolio backtesting: `Statistics/Portfolio Returns/`
   - Factor model analysis: `Statistics/Factor_Models Statistics/` (NEW)
   - Cross-sectional validation: `Statistics/Fama_MacBeth Statistics/` (NEW)
   - Publication-quality charts: `Figures and Tables/Figures/` (NEW - 24 charts)
   - Comprehensive report: `Documentations/Final Summaries/Executive_Summary.md` (NEW)
   - Presentation deck: `Documentations/Final Summaries/Presentation_Slides.md` (NEW)

## Documentation

- **[Documentations/Final Summaries/Executive_Summary.md](Documentations/Final Summaries/Executive_Summary.md)**: Comprehensive 50+ page analysis report covering methodology, results, discussion, and conclusions with all statistical findings
- **[Documentations/Final Summaries/Presentation_Slides.md](Documentations/Final Summaries/Presentation_Slides.md)**: 15-slide presentation deck with speaker notes, chart references, and timing guidelines for 10-15 minute presentation
- **[Figures and Tables/Figures/Figure Summaries (Explained).pdf](Figures and Tables/Figures/Figure Summaries (Explained).pdf)**: Detailed documentation of all 24 visualizations with metric definitions and data-driven conclusions
- **[Documentations/Data_Cleaning_Methodology.md](Documentations/Data_Cleaning_Methodology.md)**: Comprehensive documentation of data cleaning process, extraction methods, validation steps, and quality assurance procedures
- **[Documentations/walkthrough.md](Documentations/walkthrough.md)**: Step-by-step project walkthrough
- **[Documentations/Analysis Planning (Now-Redundant).md](Documentations/Analysis Planning (Now-Redundant).md)**: Project planning and approach
- **[Documentations/Criticisms.md](Documentations/Criticisms.md)**: Critical analysis and limitations
- **[Documentations/Used_Statistics(Prompt Engineering).md](Documentations/Used_Statistics(Prompt Engineering).md)**: Statistical methods documentation
- **[Statistics/Portfolio Returns/Analysis_Notes.md](Statistics/Portfolio Returns/Analysis_Notes.md)**: Portfolio construction and backtesting notes

## Important Notes

### Analysis Pipeline Evolution
This project evolved through multiple stages:
1. **Sentiment Scoring**: LLM-based sentiment analysis using Groq API
2. **Data Cleaning**: Extraction, validation, and merging with returns
3. **Portfolio Construction**: Long-short strategies with 4 configurations
4. **Statistical Validation**: Factor models (CAPM/FF3/FF5) with Newey-West SE
5. **Economic Validation**: Transaction cost analysis at multiple scenarios
6. **Cross-Sectional Validation**: Fama-MacBeth regressions
7. **Visualization**: 24 publication-quality charts for report/presentation
8. **Documentation**: Comprehensive executive summary and presentation slides

The latest additions (Steps 4-8) validate the strategy through rigorous academic methods and provide professional deliverables.

### Data Sorting
- All cleaned data files are sorted by **TICKER** (alphabetically), then by **date** (chronologically)
- This ensures consistent ordering for time-series analysis and panel data operations
- Applied in both sentiment extraction (`Extract_Data.py`) and return cleaning (`data_cleanup_returns.py`)

### Windows PowerShell Unicode Display
When running analysis scripts that output Unicode characters (Î±, Î², RÂ², emojis):
```powershell
[Console]::OutputEncoding = [System.Text.Encoding]::UTF8
$env:PYTHONIOENCODING="utf-8"
```
This ensures proper display of Greek letters and special characters in console output.